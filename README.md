# Cebrameta Avatar Pipeline

Este proyecto implementa un flujo reproducible para generar avatares hablantes a partir de una imagen fija y un guion de texto, inspirado en la experiencia de Hagen. El c√≥digo est√° dise√±ado para ser extensible y permitir el intercambio de motores de s√≠ntesis de voz y lip-sync.

## Caracter√≠sticas

- üé§ **S√≠ntesis de voz** usando Microsoft Edge TTS con voces mexicanas graves y tono institucional.
- üß† **Orquestaci√≥n completa** del pipeline: generaci√≥n de audio, animaci√≥n facial y render final.
- üß© **Componentes modulares** para reemplazar f√°cilmente motores de TTS o lip-sync.
- üìÑ **Manifiesto JSON** con metadatos de cada ejecuci√≥n y subt√≠tulos opcionales en formato SRT.
- üõ†Ô∏è **CLI basada en Typer** para ejecutar el flujo desde la terminal.

## Requisitos

- Python 3.9 o superior.
- Dependencias del sistema para los motores elegidos (GPU recomendada para SadTalker o Wav2Lip).
- `ffmpeg` disponible en el sistema para tareas de combinaci√≥n de audio/video (dependiendo del motor seleccionado).
- Acceso a Internet para el motor Edge TTS.

## Instalaci√≥n

```bash
python -m venv .venv
source .venv/bin/activate
pip install -e .
```

## Uso r√°pido

1. Prepara una imagen frontal limpia (`imagen.jpg`).
2. Crea un archivo de guion (`guion.txt`) con el texto que el avatar debe decir.
3. Ejecuta el pipeline:

```bash
cebrameta-avatar run imagen.jpg guion.txt \
  --voice institucional_grave_1 \
  --output ./outputs \
  --project demo_hagen \
  --lipsync sadtalker
```

Al finalizar, encontrar√°s el audio, el video generado y el manifiesto en la carpeta `outputs/`.

## Voces mexicanas incluidas

Consulta las voces configuradas ejecutando:

```bash
cebrameta-avatar list-voices
```

Esto mostrar√° perfiles basados en Microsoft Edge TTS ajustados con entonaci√≥n grave e institucional.

## Integraci√≥n con SadTalker

El motor por defecto es SadTalker. Debes tener disponible el comando `sadtalker` en tu entorno. Una instalaci√≥n t√≠pica se realiza clonando el repositorio oficial y ejecutando sus scripts de instalaci√≥n. Luego puedes a√±adir par√°metros adicionales con `--lipsync-extra-arg` (puedes repetir la opci√≥n varias veces) o extendiendo el CLI.

## Extender el proyecto

- **Nuevos motores TTS:** Implementa una subclase de `TTSEngine` en `avatar_pipeline/audio.py` y actualiza `build_tts_engine`.
- **Otros motores de lip-sync:** A√±ade una subclase de `LipSyncEngine` en `avatar_pipeline/lipsync.py` y extiende `build_lipsync_engine`.
- **Interfaces web o colas de procesamiento:** Usa el pipeline program√°ticamente desde `AvatarGenerationPipeline` para integrarlo en servicios mayores.

## Advertencias √©ticas

Aseg√∫rate de contar con permisos sobre la imagen y el audio generados. Respeta las regulaciones de privacidad y los derechos de autor, y comunica a los usuarios cuando interact√∫an con contenido sint√©tico.
